{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gzip\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_json(data_file):    \n",
    "    with open(data_file, 'r') as f:\n",
    "        json_records = []\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            json_records.append(record)\n",
    "    return json_records\n",
    "\n",
    "def gender_to_bin(g):\n",
    "    if g == 'M':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def to_weekday(timestamp):\n",
    "    try:\n",
    "        weekday = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\").weekday()\n",
    "    except ValueError:\n",
    "        weekday = datetime.strptime(timestamp, \"%Y-%m-%d\").weekday()\n",
    "    except TypeError:\n",
    "        weekday = 9\n",
    "    return weekday\n",
    "\n",
    "def convert_date(timestamp):\n",
    "    try:\n",
    "        res = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "    except ValueError:\n",
    "        res = datetime.strptime(timestamp, \"%Y-%m-%d\")\n",
    "    except TypeError:\n",
    "        res = 9\n",
    "    return res\n",
    "\n",
    "def get_data_pageview(page_type):\n",
    "    json_records = open_json('data/sub_data/{}'.format(page_type))\n",
    "    df = pd.DataFrame(json_records, columns=['uid', 'gender', 'page_type','timestamp'])\n",
    "    df.columns = ['uid', 'gender', '{}'.format(page_type), 'date']\n",
    "    df.gender = list(map(gender_to_bin, df.gender.values))\n",
    "    df.date = list(map(to_weekday, df.date.values))\n",
    "    df = pd.get_dummies(df, columns=['{}'.format(page_type),'date'])\n",
    "    return df.groupby(['uid','gender'], as_index=False).sum()\n",
    "\n",
    "def get_target_pageview(page_type):\n",
    "    json_records = open_json('data/sub_target/{}'.format(page_type))\n",
    "    df = pd.DataFrame(json_records, columns=['uid', 'page_type','timestamp'])\n",
    "    df.columns = ['uid', '{}'.format(page_type), 'date']\n",
    "    df.date = list(map(to_weekday, df.date.values))\n",
    "    df = pd.get_dummies(df, columns=['{}'.format(page_type),'date'])\n",
    "    return df.groupby(['uid'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5 DataFrames: catalog, purchase, pageview, target_purchase, target_pageview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.73 s, sys: 112 ms, total: 8.84 s\n",
      "Wall time: 9.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "catalog = pd.read_csv('data/catalog', usecols=['pid', 'current_price','original_price', 'category', 'sub_category', 'sub_sub_category'])\n",
    "catalog = catalog.fillna(value=0)\n",
    "catalog = catalog[catalog.current_price!=0]\n",
    "catalog['original_price'] = np.where(catalog['original_price'] == 0, catalog['current_price'], catalog['original_price'])\n",
    "catalog['diff_price'] = catalog['original_price'] - catalog['current_price']\n",
    "\n",
    "purchase_data = open_json('data/sub_data/purchase')           \n",
    "purchase = json_normalize(purchase_data, 'products', ['date','gender','uid'])\n",
    "\n",
    "pageview_data = open_json('data/sub_data/products')   \n",
    "pageview = pd.DataFrame(pageview_data, columns=['productId', 'timestamp', 'gender', 'uid'])\n",
    "pageview.columns = ['pid', 'date', 'gender', 'uid']\n",
    "\n",
    "\n",
    "purchase_data = open_json('data/sub_target/purchase')           \n",
    "target_purchase = json_normalize(purchase_data, 'products', ['date','uid'])\n",
    "\n",
    "pageview_data = open_json('data/sub_target/purchase')   \n",
    "target_pageview = pd.DataFrame(pageview_data, columns=['productId', 'timestamp', 'uid'])\n",
    "target_pageview.columns = ['pid', 'date', 'uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform gender and date into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 12 ms, total: 22.1 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "purchase.gender = list(map(gender_to_bin, purchase.gender.values))\n",
    "purchase['hour'] = purchase['date']\n",
    "purchase['month'] = purchase['date']\n",
    "#purchase['day'] = purchase['date']\n",
    "#pageview['hour'] = pageview['date']\n",
    "#pageview['month'] = pageview['date']\n",
    "#pageview['day'] = pageview['date']\n",
    "#purchase.day = list(map(lambda t:convert_date(t).day, purchase.day.values))\n",
    "purchase.month = list(map(lambda t:convert_date(t).month, purchase.month.values))\n",
    "purchase.hour = list(map(lambda t:convert_date(t).hour, purchase.hour.values))\n",
    "purchase.date = list(map(to_weekday, purchase.date.values))\n",
    "pageview.gender = list(map(gender_to_bin, pageview.gender.values))\n",
    "#pageview.day = list(map(lambda t:convert_date(t).day, pageview.day.values))\n",
    "#pageview.month = list(map(lambda t:convert_date(t).month, pageview.month.values))\n",
    "#pageview.hour = list(map(lambda t:convert_date(t).hour, pageview.hour.values))\n",
    "pageview.date = list(map(to_weekday, pageview.date.values))\n",
    "\n",
    "target_purchase['hour'] = target_purchase['date']\n",
    "target_purchase['month'] = target_purchase['date']\n",
    "#target_purchase['day'] = target_purchase['date']\n",
    "#target_pageview['hour'] = target_pageview['date']\n",
    "#target_pageview['month'] = target_pageview['date']\n",
    "#target_pageview['day'] = target_pageview['date']\n",
    "#target_purchase.day = list(map(lambda t:convert_date(t).day, target_purchase.day.values))\n",
    "target_purchase.month = list(map(lambda t:convert_date(t).month, target_purchase.month.values))\n",
    "target_purchase.hour = list(map(lambda t:convert_date(t).hour, target_purchase.hour.values))\n",
    "target_purchase.date = list(map(to_weekday, target_purchase.date.values))\n",
    "#target_pageview.day = list(map(lambda t:convert_date(t).day, target_pageview.day.values))\n",
    "#target_pageview.month = list(map(lambda t:convert_date(t).month, target_pageview.month.values))\n",
    "#target_pageview.hour = list(map(lambda t:convert_date(t).hour, target_pageview.hour.values))\n",
    "target_pageview.date = list(map(to_weekday, target_pageview.date.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dummies vars for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 460 ms, total: 1.67 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "categorical_p = ['category', 'sub_category', 'sub_sub_category', 'date','hour','month']\n",
    "categorical_v = ['category', 'sub_category', 'sub_sub_category', 'date']\n",
    "\n",
    "purchase = purchase.join(catalog.set_index('pid'), on='pid')\n",
    "purchase = pd.get_dummies(purchase, columns=categorical_p).iloc[:,1:]\n",
    "\n",
    "pageview = pageview.join(catalog.set_index('pid'), on='pid')\n",
    "pageview = pd.get_dummies(pageview, columns=categorical_v).iloc[:,1:]\n",
    "\n",
    "target_purchase = target_purchase.join(catalog.set_index('pid'), on='pid')\n",
    "target_purchase = pd.get_dummies(target_purchase, columns=categorical_p).iloc[:,1:]\n",
    "\n",
    "target_pageview = target_pageview.join(catalog.set_index('pid'), on='pid')\n",
    "target_pageview = pd.get_dummies(target_pageview, columns=categorical_v).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge users with same uid (sum entries) and join DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase.current_price = purchase.current_price.values*purchase.quantity\n",
    "purchase.original_price = purchase.original_price.values*purchase.quantity\n",
    "purchase.diff_price = purchase.diff_price.values*purchase.quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.82 s, sys: 1.87 s, total: 3.69 s\n",
      "Wall time: 8.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "purchase = purchase.groupby(['uid','gender'], as_index=False).sum()\n",
    "pageview = pageview.groupby(['uid','gender'], as_index=False).sum()\n",
    "data = purchase.join(pageview.set_index(['uid','gender']), on=['uid','gender'], rsuffix='_v')\n",
    "\n",
    "\n",
    "target_purchase = target_purchase.groupby(['uid'], as_index=False).sum()\n",
    "target_pageview = target_pageview.groupby(['uid'], as_index=False).sum()\n",
    "target_data = target_purchase.join(target_pageview.set_index('uid'), on='uid', rsuffix='_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchase.to_csv('grouped_purchase_data.csv')\n",
    "pageview.to_csv('grouped_product_pageview_data.csv')\n",
    "target_purchase.to_csv('grouped_target_purchase_data.csv')\n",
    "target_pageview.to_csv('grouped_target_product_pageview_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search = get_data_pageview('home')\n",
    "target_search = get_target_pageview('home')\n",
    "\n",
    "data2 = data.join(search.set_index(['uid','gender']), on=['uid','gender'], rsuffix='_s')\n",
    "target_data2 = target_data.join(target_search.set_index('uid'), on='uid', rsuffix='_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14213"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search.uid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna(value=0)\n",
    "target_data = target_data.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = data.columns[2:]\n",
    "target = data.columns[1]\n",
    "features2 = target_data.columns[1:]\n",
    "features = list(set(features)&set(features2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[features]\n",
    "Y = data[target]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=23492)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769458987784 0.808467449616 0.756076647811\n",
      "CPU times: user 2.33 s, sys: 24 ms, total: 2.36 s\n",
      "Wall time: 2.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(x_train, y_train)\n",
    "y_pred = forest.predict(x_test)\n",
    "score1 = metrics.accuracy_score(y_test, y_pred)\n",
    "score2 = metrics.f1_score(y_test, y_pred, average='binary')\n",
    "score3 = metrics.roc_auc_score(y_test, y_pred)\n",
    "#joblib.dump(forest, '83.pkl')\n",
    "print score1, score2, score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77294938918 0.811912678907 0.759096883389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100,learning_rate=1.0,max_depth=1,random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "score1 = metrics.accuracy_score(y_test, y_pred)\n",
    "score2 = metrics.f1_score(y_test, y_pred, average='binary')\n",
    "score3 = metrics.roc_auc_score(y_test, y_pred)\n",
    "print score1, score2, score3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = target_data[features]\n",
    "answer = forest.predict(X)\n",
    "users = target_data.uid.values\n",
    "ans = []\n",
    "for i,u in enumerate(users):\n",
    "    if answer[i]:\n",
    "        g = 'M'\n",
    "    else:\n",
    "        g = 'F'\n",
    "    obj = {'a':u, 'b':g}\n",
    "    ans.append(obj)\n",
    "    \n",
    "import csv\n",
    "\n",
    "with open('ans10.csv', 'wb') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=['a','b'])\n",
    "    for obj in ans:\n",
    "        w.writerow(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
