{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gzip\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_json(data_file):    \n",
    "    with open(data_file, 'r') as f:\n",
    "        json_records = []\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            json_records.append(record)\n",
    "    return json_records\n",
    "\n",
    "def gender_to_bin(g):\n",
    "    if g == 'M':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def bin_to_gender(g):\n",
    "    if g == 1:\n",
    "        return 'M'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "def to_weekday(timestamp):\n",
    "    try:\n",
    "        weekday = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\").weekday()\n",
    "    except ValueError:\n",
    "        weekday = datetime.strptime(timestamp, \"%Y-%m-%d\").weekday()\n",
    "    except TypeError:\n",
    "        weekday = 1\n",
    "    return weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5 DataFrames: catalog, purchase, pageview, target_purchase, target_pageview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 104 ms, total: 10.3 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "catalog = pd.read_csv('data/catalog.gz', usecols=['pid', 'current_price', 'category', 'sub_category', 'sub_sub_category'])\n",
    "for i,val in enumerate(catalog.current_price.values):\n",
    "    if np.isnan(val):\n",
    "        catalog.current_price.values[i] = 0\n",
    "\n",
    "purchase_data = open_json('data/purchase_data')           \n",
    "purchase = json_normalize(purchase_data, 'products', ['date','gender','uid'])\n",
    "\n",
    "pageview_data = open_json('data/products_data')   \n",
    "pageview = pd.DataFrame(pageview_data, columns=['productId', 'timestamp', 'gender', 'uid'])\n",
    "pageview.columns = ['pid', 'date', 'gender', 'uid']\n",
    "\n",
    "\n",
    "purchase_data = open_json('data/purchase_new_target')           \n",
    "target_purchase = json_normalize(purchase_data, 'products', ['date','uid'])\n",
    "\n",
    "pageview_data = open_json('data/products_new_target')   \n",
    "target_pageview = pd.DataFrame(pageview_data, columns=['productId', 'timestamp', 'uid'])\n",
    "target_pageview.columns = ['pid', 'date', 'uid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform gender and date into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.8 s, sys: 8 ms, total: 21.8 s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "purchase.gender = list(map(gender_to_bin, purchase.gender.values))\n",
    "purchase.date = list(map(to_weekday, purchase.date.values))\n",
    "\n",
    "pageview.gender = list(map(gender_to_bin, pageview.gender.values))\n",
    "pageview.date = list(map(to_weekday, pageview.date.values))\n",
    "\n",
    "\n",
    "target_purchase.date = list(map(to_weekday, target_purchase.date.values))\n",
    "target_pageview.date = list(map(to_weekday, target_pageview.date.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dummies vars for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.36 s, sys: 288 ms, total: 1.65 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "categorical = ['category', 'sub_category', 'sub_sub_category', 'date']\n",
    "\n",
    "purchase = purchase.join(catalog.set_index('pid'), on='pid')\n",
    "purchase = pd.get_dummies(purchase, columns=categorical).iloc[:,1:]\n",
    "\n",
    "pageview = pageview.join(catalog.set_index('pid'), on='pid')\n",
    "pageview = pd.get_dummies(pageview, columns=categorical).iloc[:,1:]\n",
    "\n",
    "target_purchase = target_purchase.join(catalog.set_index('pid'), on='pid')\n",
    "target_purchase = pd.get_dummies(target_purchase, columns=categorical).iloc[:,1:]\n",
    "\n",
    "target_pageview = target_pageview.join(catalog.set_index('pid'), on='pid')\n",
    "target_pageview = pd.get_dummies(target_pageview, columns=categorical).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge users with same uid (sum entries) and join DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12687"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_purchase.uid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.54 s, sys: 1.79 s, total: 4.34 s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#quantity = purchase.pop('quantity')\n",
    "purchase = purchase.groupby(['uid','gender'], as_index=False).sum()\n",
    "pageview = pageview.groupby(['uid','gender'], as_index=False).sum()\n",
    "data = purchase.join(pageview.set_index(['uid','gender']), on=['uid','gender'], rsuffix='_v')\n",
    "\n",
    "\n",
    "target_purchase = target_purchase.groupby(['uid'], as_index=False).sum()\n",
    "target_pageview = target_pageview.groupby(['uid'], as_index=False).sum()\n",
    "target_data = target_purchase.join(target_pageview.set_index('uid'), on='uid', rsuffix='_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna(value=0)\n",
    "target_data = target_data.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = data.columns[3:]\n",
    "target = data.columns[1]\n",
    "features2 = target_data.columns[2:]\n",
    "features = list(set(features)&set(features2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[features]\n",
    "Y = data[target]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.51 s, sys: 284 ms, total: 3.8 s\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(x_train, y_train)\n",
    "y_pred = forest.predict(x_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78917975567190224"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = target_data[features]\n",
    "answer = forest.predict(X)\n",
    "users = target_data.uid.values\n",
    "ans = []\n",
    "for i,u in enumerate(users):\n",
    "    if answer[i]:\n",
    "        g = 'M'\n",
    "    else:\n",
    "        g = 'F'\n",
    "    obj = {'a':u, 'b':g}\n",
    "    ans.append(obj)\n",
    "    \n",
    "import csv\n",
    "\n",
    "with open('ans6.csv', 'wb') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=['a','b'])\n",
    "    for obj in ans:\n",
    "        w.writerow(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = target_data[features]\n",
    "answer = forest.predict(X)\n",
    "users = target_data.uid.values\n",
    "ans = []\n",
    "for i,u in enumerate(users):\n",
    "    if answer[i]:\n",
    "        g = 'M'\n",
    "    else:\n",
    "        g = 'F'\n",
    "    obj = {'a':u}\n",
    "    ans.append(obj)\n",
    "    \n",
    "import csv\n",
    "\n",
    "with open('usu.csv', 'wb') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=['a'])\n",
    "    for obj in ans:\n",
    "        w.writerow(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
