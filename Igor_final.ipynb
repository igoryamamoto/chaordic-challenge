{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gzip\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_json(data_file):    \n",
    "    with open(data_file, 'r') as f:\n",
    "        json_records = []\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            json_records.append(record)\n",
    "    return json_records\n",
    "\n",
    "def gender_to_bin(g):\n",
    "    if g == 'M':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def to_weekday(timestamp):\n",
    "    try:\n",
    "        weekday = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\").weekday()\n",
    "    except ValueError:\n",
    "        weekday = datetime.strptime(timestamp, \"%Y-%m-%d\").weekday()\n",
    "    except TypeError:\n",
    "        weekday = -1\n",
    "    return weekday\n",
    "\n",
    "def convert_date(timestamp):\n",
    "    try:\n",
    "        res = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "    except ValueError:\n",
    "        res = datetime.strptime(timestamp, \"%Y-%m-%d\")\n",
    "    except TypeError:\n",
    "        res = -1\n",
    "    return res\n",
    "\n",
    "def get_data_pageview(page_type):\n",
    "    json_records = open_json('data/sub_data/{}'.format(page_type))\n",
    "    df = pd.DataFrame(json_records, columns=['uid', 'gender', 'page_type','timestamp'])\n",
    "    df.columns = ['uid', 'gender', '{}'.format(page_type), 'date']\n",
    "    df.gender = list(map(gender_to_bin, df.gender.values))\n",
    "    df.date = list(map(to_weekday, df.date.values))\n",
    "    df = pd.get_dummies(df, columns=['{}'.format(page_type),'date'])\n",
    "    return df.groupby(['uid','gender'], as_index=False).sum()\n",
    "\n",
    "def get_target_pageview(page_type):\n",
    "    json_records = open_json('data/sub_target/{}'.format(page_type))\n",
    "    df = pd.DataFrame(json_records, columns=['uid', 'page_type','timestamp'])\n",
    "    df.columns = ['uid', '{}'.format(page_type), 'date']\n",
    "    df.date = list(map(to_weekday, df.date.values))\n",
    "    df = pd.get_dummies(df, columns=['{}'.format(page_type),'date'])\n",
    "    return df.groupby(['uid'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5 DataFrames: catalog, purchase, pageview, target_purchase, target_pageview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.28 s, sys: 164 ms, total: 9.44 s\n",
      "Wall time: 9.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "catalog = pd.read_csv('data/catalog', usecols=['pid', 'current_price','original_price', 'category', 'sub_category', 'sub_sub_category'])\n",
    "catalog = catalog.fillna(value=0)\n",
    "catalog = catalog[catalog.current_price!=0]\n",
    "catalog['original_price'] = np.where(catalog['original_price'] == 0, catalog['current_price'], catalog['original_price'])\n",
    "catalog['diff_price'] = catalog['original_price'] - catalog['current_price']\n",
    "\n",
    "purchase_data = open_json('data/sub_data/purchase')           \n",
    "purchase = json_normalize(purchase_data, 'products', ['date','gender','uid'])\n",
    "\n",
    "pageview_data = open_json('data/sub_data/products')   \n",
    "pageview = pd.DataFrame(pageview_data, columns=['productId', 'timestamp', 'gender', 'uid'])\n",
    "pageview.columns = ['pid', 'date', 'gender', 'uid']\n",
    "\n",
    "\n",
    "purchase_data = open_json('data/sub_target/purchase')           \n",
    "target_purchase = json_normalize(purchase_data, 'products', ['date','uid'])\n",
    "\n",
    "pageview_data = open_json('data/sub_target/products')   \n",
    "target_pageview = pd.DataFrame(pageview_data, columns=['productId', 'timestamp', 'uid'])\n",
    "target_pageview.columns = ['pid', 'date', 'uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catalog.to_csv('catalog_transformed.csv')\n",
    "purchase.to_csv('raw_purchase.csv')\n",
    "pageview.to_csv('raw_product_pageview_data.csv')\n",
    "target_purchase.to_csv('raw_target_purchase.csv')\n",
    "target_pageview.to_csv('raw_target_product_pageview.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform gender and date into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 s, sys: 8 ms, total: 24.8 s\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "purchase.gender = list(map(gender_to_bin, purchase.gender.values))\n",
    "#purchase['hour'] = purchase['date']\n",
    "purchase['month'] = purchase['date']\n",
    "#purchase['day'] = purchase['date']\n",
    "#pageview['hour'] = pageview['date']\n",
    "#pageview['month'] = pageview['date']\n",
    "#pageview['day'] = pageview['date']\n",
    "#purchase.day = list(map(lambda t:convert_date(t).day, purchase.day.values))\n",
    "purchase.month = list(map(lambda t:convert_date(t).month, purchase.month.values))\n",
    "#purchase.hour = list(map(lambda t:convert_date(t).hour, purchase.hour.values))\n",
    "purchase.date = list(map(to_weekday, purchase.date.values))\n",
    "pageview.gender = list(map(gender_to_bin, pageview.gender.values))\n",
    "#pageview.day = list(map(lambda t:convert_date(t).day, pageview.day.values))\n",
    "#pageview.month = list(map(lambda t:convert_date(t).month, pageview.month.values))\n",
    "#pageview.hour = list(map(lambda t:convert_date(t).hour, pageview.hour.values))\n",
    "pageview.date = list(map(to_weekday, pageview.date.values))\n",
    "\n",
    "#target_purchase['hour'] = target_purchase['date']\n",
    "target_purchase['month'] = target_purchase['date']\n",
    "#target_purchase['day'] = target_purchase['date']\n",
    "#target_pageview['hour'] = target_pageview['date']\n",
    "#target_pageview['month'] = target_pageview['date']\n",
    "#target_pageview['day'] = target_pageview['date']\n",
    "#target_purchase.day = list(map(lambda t:convert_date(t).day, target_purchase.day.values))\n",
    "target_purchase.month = list(map(lambda t:convert_date(t).month, target_purchase.month.values))\n",
    "#target_purchase.hour = list(map(lambda t:convert_date(t).hour, target_purchase.hour.values))\n",
    "target_purchase.date = list(map(to_weekday, target_purchase.date.values))\n",
    "#target_pageview.day = list(map(lambda t:convert_date(t).day, target_pageview.day.values))\n",
    "#target_pageview.month = list(map(lambda t:convert_date(t).month, target_pageview.month.values))\n",
    "#target_pageview.hour = list(map(lambda t:convert_date(t).hour, target_pageview.hour.values))\n",
    "target_pageview.date = list(map(to_weekday, target_pageview.date.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 6, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pageview.date.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchase.to_csv('transformed_purchase.csv')\n",
    "pageview.to_csv('transformed_product_pageview_data.csv')\n",
    "target_purchase.to_csv('transformed_target_purchase.csv')\n",
    "target_pageview.to_csv('transformed_target_product_pageview.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dummies vars for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 s, sys: 212 ms, total: 1.59 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "categorical_p = ['category', 'sub_category', 'sub_sub_category', 'date','month']\n",
    "categorical_v = ['category', 'sub_category', 'sub_sub_category', 'date']\n",
    "\n",
    "purchase = purchase.join(catalog.set_index('pid'), on='pid')\n",
    "purchase = pd.get_dummies(purchase, columns=categorical_p).iloc[:,1:]\n",
    "\n",
    "pageview = pageview.join(catalog.set_index('pid'), on='pid')\n",
    "pageview = pd.get_dummies(pageview, columns=categorical_v).iloc[:,1:]\n",
    "\n",
    "target_purchase = target_purchase.join(catalog.set_index('pid'), on='pid')\n",
    "target_purchase = pd.get_dummies(target_purchase, columns=categorical_p).iloc[:,1:]\n",
    "\n",
    "target_pageview = target_pageview.join(catalog.set_index('pid'), on='pid')\n",
    "target_pageview = pd.get_dummies(target_pageview, columns=categorical_v).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchase.to_csv('dummy_purchase.csv')\n",
    "pageview.to_csv('dummy_product_pageview_data.csv')\n",
    "target_purchase.to_csv('dummy_target_purchase.csv')\n",
    "target_pageview.to_csv('dummy_target_product_pageview.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge users with same uid (sum entries) and join DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchase.current_price = purchase.current_price.values*purchase.quantity\n",
    "purchase.original_price = purchase.original_price.values*purchase.quantity\n",
    "purchase.diff_price = purchase.diff_price.values*purchase.quantity\n",
    "\n",
    "target_purchase.current_price = target_purchase.current_price.values*target_purchase.quantity\n",
    "target_purchase.original_price = target_purchase.original_price.values*target_purchase.quantity\n",
    "target_purchase.diff_price = target_purchase.diff_price.values*target_purchase.quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 s, sys: 1.09 s, total: 2.74 s\n",
      "Wall time: 3.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "purchase = purchase.groupby(['uid','gender'], as_index=False).sum()\n",
    "pageview = pageview.groupby(['uid','gender'], as_index=False).sum()\n",
    "data = purchase.join(pageview.set_index(['uid','gender']), on=['uid','gender'], rsuffix='_v')\n",
    "\n",
    "\n",
    "target_purchase = target_purchase.groupby(['uid'], as_index=False).sum()\n",
    "target_pageview = target_pageview.groupby(['uid'], as_index=False).sum()\n",
    "target_data = target_purchase.join(target_pageview.set_index('uid'), on='uid', rsuffix='_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchase.to_csv('grouped_purchase.csv')\n",
    "pageview.to_csv('grouped_product_pageview.csv')\n",
    "target_purchase.to_csv('grouped_target_purchase.csv')\n",
    "target_pageview.to_csv('grouped_target_product_pageview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('final_data.csv')\n",
    "target_data.to_csv('final_target_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#search = get_data_pageview('search')\n",
    "#target_search = get_target_pageview('search')\n",
    "#data2 = data.join(search.set_index(['uid','gender']), on=['uid','gender'], rsuffix='_s')\n",
    "#target_data2 = target_data.join(target_search.set_index('uid'), on='uid', rsuffix='_s')\n",
    "\n",
    "#home = get_data_pageview('home')\n",
    "#target_home = get_target_pageview('home')\n",
    "#data2 = data2.join(home.set_index(['uid','gender']), on=['uid','gender'], rsuffix='_s')\n",
    "#target_data2 = target_data2.join(target_home.set_index('uid'), on='uid', rsuffix='_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14213"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search.uid.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna(value=0)\n",
    "target_data = target_data.fillna(value=0)\n",
    "features = data.columns[2:]\n",
    "target = data.columns[1]\n",
    "features2 = target_data.columns[1:]\n",
    "features = list(set(features)&set(features2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = np.array(features)\n",
    "f.tofile('features.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ultimate_data = data[[target]+features]\n",
    "ultimate_target = target_data[features]\n",
    "ultimate_data.to_csv('ultimate_data.csv',index=False)\n",
    "ultimate_target.to_csv('ultimate_target.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data2 = data2.fillna(value=0)\n",
    "#target_data2 = target_data2.fillna(value=0)\n",
    "#features = data2.columns[2:]\n",
    "#target = data2.columns[1]\n",
    "#features2 = target_data2.columns[1:]\n",
    "#features = list(set(features)&set(features2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[features]\n",
    "Y = data[target]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = data2[features]\n",
    "#Y = data2[target]\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789128595601 0.821932487944 0.77914325534\n",
      "CPU times: user 3.34 s, sys: 32 ms, total: 3.38 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(x_train, y_train)\n",
    "y_pred = forest.predict(x_test)\n",
    "score1 = metrics.accuracy_score(y_test, y_pred)\n",
    "score2 = metrics.f1_score(y_test, y_pred, average='binary')\n",
    "score3 = metrics.roc_auc_score(y_test, y_pred)\n",
    "#joblib.dump(forest, '83.pkl')\n",
    "print score1, score2, score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790397631134 0.822877569258 0.780574313927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100,learning_rate=1.0,max_depth=1,random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "score1 = metrics.accuracy_score(y_test, y_pred)\n",
    "score2 = metrics.f1_score(y_test, y_pred, average='binary')\n",
    "score3 = metrics.roc_auc_score(y_test, y_pred)\n",
    "print score1, score2, score3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targ_X = target_data[features]\n",
    "answer = clf.predict(targ_X)\n",
    "users = target_data.uid.values\n",
    "ans = []\n",
    "for i,u in enumerate(users):\n",
    "    if answer[i]:\n",
    "        g = 'M'\n",
    "    else:\n",
    "        g = 'F'\n",
    "    obj = {'a':u, 'b':g}\n",
    "    ans.append(obj)\n",
    "    \n",
    "import csv\n",
    "\n",
    "with open('ans14.csv', 'wb') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=['a','b'])\n",
    "    for obj in ans:\n",
    "        w.writerow(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_X = target_data[features]\n",
    "target_X.to_csv('target_X.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = 100\n",
    "targ_X = target_data[features]\n",
    "hack_answer = clf.predict(targ_X)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "for i in range(it-1):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=i)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score1 = metrics.accuracy_score(y_test, y_pred)\n",
    "    score = score + score1\n",
    "    new = clf.predict(targ_X)\n",
    "    hack_answer = hack_answer + new\n",
    "hack_answer = np.round((1.0*hack_answer)/it)\n",
    "score = (1.0*score)/it\n",
    "\n",
    "users = target_data.uid.values\n",
    "ans = []\n",
    "for i,u in enumerate(users):\n",
    "    if hack_answer[i]:\n",
    "        g = 'M'\n",
    "    else:\n",
    "        g = 'F'\n",
    "    obj = {'a':u, 'b':g}\n",
    "    ans.append(obj)\n",
    "    \n",
    "import csv\n",
    "\n",
    "with open('hack1.csv', 'wb') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=['a','b'])\n",
    "    for obj in ans:\n",
    "        w.writerow(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
